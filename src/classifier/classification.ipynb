{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aea6e3c3-e779-4534-980e-ee53dff90444",
   "metadata": {},
   "source": [
    "# Image classification \n",
    "\n",
    "For classification purpose, the output layer needs to be a FC layer with its output the class number. \n",
    "\n",
    "ViT needs to append a FC layer (head) because its strucute was originally designed for NLP; for other CNN based model, can modify the last layer in-place.\n",
    "\n",
    "Fine-tuning can:\n",
    "1. Update the parameters of the whole model\n",
    "2. Only update the last layer (or certain layers). Can make these parts require_grad=False.\n",
    "\n",
    "Notes:\n",
    "1. By default, pretrained PyTorch models (huggingface) are built considering input data (N,C,H,W) as the first layer or embedding layer. Model itself is built with weights only taking a single data (C,H, W) because no need to duplicated the parameters. For example, the ViT model used in this notebook handles batches in the model embedding layer.\n",
    "2. PyTorch dataloader will prepare data in correct batch (N,C,H,W). Then you can write outputs=model(batch_data). It will feed each data into the \"actual\" model, calculate the score per data,and ouput the results in batch.\n",
    "3. Then you can use criterion to calculate a single loss score per minibatch, and update the weights per minibatch (instead of the whole dataset).\n",
    "4. PyTorch-Lightning handles batch inside the trainer() class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b16a1c-2091-45da-bf36-2a1af09b59f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34a1441-5ae0-4a2f-a823-2e1c52433ec1",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f0c0b5-0067-4ac9-8375-fa61ba7f02aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = 'vit_p16' #\"vit_p32\" #\"resnet\" #\"squeezenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 16\n",
    "\n",
    "# Number of epochs to train for \n",
    "num_epochs = 50\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model, when True we only update the reshaped layer params\n",
    "feature_extract = True\n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# output_dir\n",
    "out_dir = './discriminator_data/checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bec04d",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd7176b-ce02-45a0-af86-f346d65b8393",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import myDataloader\n",
    "\n",
    "#dataroot = \"./discriminator_data/data\"\n",
    "dataroot = \"/lovelace/zhuowen/diffusers/als/40k_generated/als_2400_labeled\"\n",
    "input_size = 224\n",
    "transform=transforms.Compose([transforms.Resize(input_size),\n",
    "                              transforms.CenterCrop(input_size),\n",
    "                              transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                             ])\n",
    "dataloaders =  myDataloader(root=dataroot, \n",
    "                            batch_size=batch_size, \n",
    "                            transform=transform,\n",
    "                            num_workers = 2,\n",
    "                            split=[0.7, 0.3],\n",
    "                            from_subfolders=True)\n",
    "\n",
    "train_dataloader, val_dataloader = dataloaders.dataloader()\n",
    "print(len(train_dataloader), len(val_dataloader))\n",
    "    \n",
    "dataloaders.plot_dataloader(train_dataloader, device)\n",
    "\n",
    "# Create training and validation dataloaders\n",
    "dataloaders_dict = {'train': train_dataloader, 'validation':val_dataloader}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a64ff-583e-4ea7-a9ae-56009b45ca6b",
   "metadata": {},
   "source": [
    "## Training example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ddd38-b50f-477c-86a4-6b8a0e64e073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from model_utils import myModels\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = myModels.initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "#print(model_ft)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are \n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444c5a8-bc2c-41c8-b179-dbe9143f5190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pipeline_utils import Trainer\n",
    "\n",
    "# define optimizer and loss\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "trainer = Trainer(model_ft, \n",
    "                  dataloaders_dict, \n",
    "                  criterion, \n",
    "                  optimizer_ft,\n",
    "                  device=device, \n",
    "                  num_epochs=num_epochs, \n",
    "                  is_inception=(model_name==\"inception\"), \n",
    "                  verbose=True\n",
    "                  )\n",
    "model_ft, hist = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7ff7e5-1dd9-450c-98ae-858888b3cc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_history(10, save_fig=True, out_name=out_dir+'history_'+model_name+'_'+str(num_epochs)+'epochs_classifier.png')\n",
    "trainer.save_results(out_dir, model_name=model_name+'_'+str(num_epochs)+'_epochs_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f761abf-fcf5-4fcf-b635-c3f095dd4384",
   "metadata": {},
   "source": [
    "# Evaluation example (vit_16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c949016-fd4a-4efe-b734-ec945ebd98f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from pipeline_utils import Evaluation\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder(root=\"/lovelace/zhuowen/diffusers/als/40k_generated/als_2400_labeled\", \n",
    "                                                   transform=transform)\n",
    "eval_dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa00fe3-4b13-4839-a61a-1cfa56d9c953",
   "metadata": {},
   "outputs": [],
   "source": [
    "vit_p16 = torch.load(out_dir+'vit_p16_50epochs.pth')\n",
    "vit_p16_eval = Evaluation(vit_p16, eval_dataloader, threshold=0.56, device=device)\n",
    "vit_p16_eval.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905d3101-32bf-4101-a322-409aa8b31f7e",
   "metadata": {},
   "source": [
    "## Inferencing example (vit_16x16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25fb33a-6260-4bb9-b7c0-2a17d400c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_utils import myDataset\n",
    "from pipeline_utils import Inference\n",
    "import glob\n",
    "\n",
    "test_data_path = '/lovelace/zhuowen/diffusers/als/40k_generated/prompt1/'\n",
    "filepaths = glob.glob(test_data_path+'/*')\n",
    "\n",
    "test_dataset = myDataset(root=test_data_path, \n",
    "                         transform=transform,\n",
    "                         return_filepath=True)\n",
    "\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                              batch_size=batch_size,\n",
    "                                              shuffle=False,\n",
    "                                              num_workers=0,\n",
    "                                              drop_last=False,\n",
    "                                              prefetch_factor=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec462d-38e2-4fad-94e6-11ed38c50fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data_path = '/lovelace/zhuowen/diffusers/als/40k_generated/prompt1/'\n",
    "\n",
    "# load trained model \n",
    "vit_p16 = torch.load(out_dir+'vit_p16_50epochs.pth')\n",
    "vit_p16_infer = Inference(vit_p16, test_dataloader, threshold=0.56, device=device, filepaths=filepaths)\n",
    "vit_p16_infer.next_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f19f44",
   "metadata": {},
   "source": [
    "## Ensemble classification and evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e9207",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
